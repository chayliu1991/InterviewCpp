# 并发编程基础

在 C++ 语言里，线程就是一个能够独立运行的函数。任何程序一开始就有一个主线程，它从 main() 开始运行。主线程可以调用接口函数，创建 出子线程。子线程会立即脱离主线程的控制流程，单独运行，但共享主线程的数据。程序创建出多个子线程，执行多个不同的函数，也就成了多线程。

“读而不写”就不会有数据竞争。所以，在 C++ 多线程编程里读取 const 变量总是安全的，对类调用 const 成员函数、对容器调用只读算法也总是线程安全的。

std::thread 用于创建一个执行的线程实例，所以它是一切并发编程的基础。

C++ 标准库里有专门的线程类 thread，使用它就可以简单地创建线程，在名字空间 std::this_thread 里，还有 yield()、get_id()、sleep_for()、sleep_until() 、hardware_concurrency() 等几个方便的管理函数。

## 仅调用一次

```
int main()
{
	static std::once_flag flag;
	auto f = []()
	{
		std::call_once(flag, []() {
			std::cout << "call only once" << std::endl;
		});
	};

	std::thread t1(f);
	std::thread t2(f);

	t1.join();
	t2.join();

	return 0;
}
```

## 线程局部存储

读写全局（或者局部静态）变量是另一个比较常见的数据竞争场景，因为共享数据，多线程操作时就有可能导致状态不一致。

有的时候，全局变量并不一定是必须共享的，可能仅仅是 为了方便线程传入传出数据，或者是本地 cache，而不是为了共享所有权。换句话说，这应该是线程独占所有权，不应该在多线程之间共同拥有，术语叫“线程局部存 储”。这个功能在 C++ 里由关键字 thread_local 实现，它是一个和 static、extern 同级的变量 存储说明，有 thread_local 标记的变量在每个线程里都会有一个独立的副本，是“线程独 占”的，所以就不会有竞争读写的问题。

```
int main()
{
	thread_local int n = 0; //@ 线程局部存储变量

	auto f = [&](int x)
	{
		n += x; //@ 使用线程局部变量，互不影响
		std::cout << n << std::endl;
	};

	std::thread t1(f,10);
	std::thread t2(f,20);

	t1.join();
	t2.join();

	return 0;
}
```



# 互斥量

mutex 只可默认构造，不可拷贝（或移动），不可赋值，主要提供的方法是：  

- lock：锁定，锁已经被其他线程获得时则阻塞执行
- try_lock：尝试锁定，获得锁返回 true，在锁被其他线程获得时返回 false
- unlock：解除锁定（只允许在已获得锁时调用）  

允许同一线程可以无阻塞地多次加锁外（也必须有对应数量的解锁操作），recursive_mutex 的其他行为和 mutex 一致。  

除了 mutex 和 recursive_mutex，C++ 标准库还提供了：

- timed_mutex：允许锁定超时的互斥量
- recursive_timed_mutex：允许锁定超时的递归互斥量
- shared_mutex：允许共享和独占两种获得方式的互斥量
- shared_timed_mutex：允许共享和独占两种获得方式的、允许锁定超时的互斥量  



# 条件变量



# 期物

## future

```
int work()
{
	std::this_thread::sleep_for(std::chrono::seconds(1));
	return 42;
}

int main()
{
	auto fut = std::async(std::launch::async,work);
	std::cout << "ans is:" << fut.get() << std::endl;

	return 0;
}
```

一个 future 上只能调用一次 get 函数，第二次调用为未定义行为，通常导致程序崩溃。  

这样一来，自然一个 future 是不能直接在多个线程里用的。 但是可以使用 shared_future 解决此问题， 要么直接拿 future 来移动构造一个 shared_future [12]，要么调用 future 的 share 方法来生成一个 shared_future，结果就可以在多个线程里用了——当然，每个 shared_future 上仍然还是只能调用一次 get 函数。  

## promise

```
void work(std::promise<int> pro)
{
	std::this_thread::sleep_for(std::chrono::seconds(1));
	pro.set_value(42);
}

int main()
{
	std::promise<int> prom;
	auto fut = prom.get_future();

	std::thread t(work, std::move(prom));

	while (1)
	{
		auto && status = fut.wait_for(std::chrono::milliseconds(300));
		if (status == std::future_status::timeout)
			std::cout << "wait timeout ..." << std::endl;
		else if (status == std::future_status::ready)
			break;
	}

	std::cout << "ans is:" << fut.get() << std::endl;

	t.join();

	return 0;
}
```

promise 和 future 在这里成对出现，可以看作是一个一次性管道：有人需要兑现承诺，往 promise 里放东西（set_value）；有人就像收期货一样，到时间去 future  里拿（get）就行了。我们把 prom 移动给新线程，这样老线程就完全不需要管理它的生命周期了。

一组promise 和 future 只能使用一次，既不能重复设，也不能重复取。

## package_task

```
int work()
{
	std::this_thread::sleep_for(std::chrono::seconds(1));
	return 42;
}

int main()
{
	std::packaged_task<int()> task(work);
	auto fut = task.get_future();

	std::thread t(std::move(task));

	while (1)
	{
		auto && status = fut.wait_for(std::chrono::milliseconds(300));
		if (status == std::future_status::timeout)
			std::cout << "wait timeout ..." << std::endl;
		else if (status == std::future_status::ready)
			break;
	}

	std::cout << "ans is:" << fut.get() << std::endl;

	t.join();

	return 0;
}
```

打包任务里打包的是一个函数，模板参数就是一个函数类型。跟 thread、future、promise 一样，packaged_task 只能移动，不能复制。它是个函数对象，可以像正常函数一样被执行，也可以传递给 thread 在新线程中执行。它的特别地方，自然也是你可以从它得到一个未来量了。通过这个未来量，你可以得到这个打包任务的返回值，或者，至少知道这个打包任务已经执行结束了。  

# 原子操作与内存模型

## 原子操作

所谓原子（atomic），在多线程领域里的意思就是不可分的。操作要么完成，要么未完成，不能被任何外部操作打断，总是有一个确定的、完整的状态。所以也就不会存在竞争读写的问题，不需要使用互斥量来同步，成本也就更低。



## 一致性模型

每个线程可以对应为一个集群节点，而线程间的通信也几乎等价于集群节点间的通信。削弱进程间的同步条件，通常会考虑四种不同的一致性模型。

### 线性一致性

又称强一致性或原子一致性。它要求任何一次读操作都能读到某个数据的最近一次写的数据，并且所有线程的操作顺序与全局时钟下的顺序是一致的。

```
        x.store(1)      x.load()
T1 ---------+----------------+------>

T2 -------------------+------------->
                x.store(2)
```

在这种情况下线程 T1, T2 对 x 的两次写操作是原子的，且 x.store(1) 是严格的发生在 x.store(2) 之前，x.store(2) 严格的发生在 x.load() 之前。

### 顺序一致性

同样要求任何一次读操作都能读到数据最近一次写入的数据，但未要求与全局时钟的顺序一致。

```
        x.store(1)  x.store(3)   x.load()
T1 ---------+-----------+----------+----->
T2 ---------------+---------------------->
              x.store(2)
```

或者：

```
        x.store(1)  x.store(3)   x.load()
T1 ---------+-----------+----------+----->
T2 ------+------------------------------->
      x.store(2)
```

在顺序一致性的要求下，x.load() 必须读到最近一次写入的数据，因此 x.store(2) 与 x.store(1) 并无任何先后保障，即只要 T2 的 x.store(2) 发生在 x.store(3) 之前即可。

### 因果一致性

它的要求进一步降低，只需要有因果关系的操作顺序得到保障，而非因果关系的操作顺序则不做要求。

```
      a = 1      b = 2
T1 ----+-----------+---------------------------->
T2 ------+--------------------+--------+-------->
      x.store(3)         c = a + b    y.load()
```

或者：

```
      a = 1      b = 2
T1 ----+-----------+---------------------------->
T2 ------+--------------------+--------+-------->
      x.store(3)          y.load()   c = a + b
```

亦或者:

```
     b = 2       a = 1
T1 ----+-----------+---------------------------->
T2 ------+--------------------+--------+-------->
      y.load()            c = a + b  x.store(3)
```

上面给出的三种例子都是属于因果一致的，因为整个过程中，只有 c 对 a 和 b 产生依赖，而 x 和 y 在此例子中表现为没有关系。

### 最终一致性

是最弱的一致性要求，它只保障某个操作在未来的某个时间节点上会被观察到，但并未要求被观察到的时间。因此我们甚至可以对此条件稍作加强，例如规定某个操作被观察到的时间总是有界的。

```
    x.store(3)  x.store(4)
T1 ----+-----------+-------------------------------------------->
T2 ---------+------------+--------------------+--------+-------->
         x.read()      x.read()           x.read()   x.read()
```

在上面的情况中，如果我们假设 x 的初始值为 0，则 T2 中四次 x.read() 结果可能但不限于以下情况：

```
3 4 4 4 //@ x 的写操作被很快观察到
0 3 3 4 //@ x 的写操作被观察到的时间存在一定延迟
0 0 0 4 //@ 最后一次读操作读到了 x 的最终值，但此前的变化并未观察到
0 0 0 0 //@ 在当前时间段内 x 的写操作均未被观察到，但未来某个时间点上一定能观察到 x 为 4 的情况
```

## 内存顺序

为了追求极致的性能，实现各种强度要求的一致性，C++11 为原子操作定义了六种不同的内存顺序 `std::memory_order` 的选项，表达了四种多线程间的同步模型。

### 宽松模型

类型通过 `std::memory_order_relaxed` 指定。在此模型下，单个线程内的原子操作都是顺序执行的，不允许指令重排，但不同线程间原子操作的顺序是任意的。

```
	std::atomic<int> counter = { 0 };
	std::vector<std::thread> vt;
	for (int i = 0; i < 100; ++i) {
		vt.emplace_back([&counter]() {
			counter.fetch_add(1, std::memory_order_relaxed);
		});
	}

	for (auto& t : vt) {
		t.join();
	}
	std::cout << "current counter:" << counter << std::endl;
```

### 释放/消费模型

在此模型中，我们开始限制进程间的操作顺序，如果某个线程需要修改某个值，但另一个线程会对该值的某次操作产生依赖，即后者依赖前者。具体而言，线程 A 完成了三次对 `x` 的写操作，线程 B 仅依赖其中第三次 x 的写操作，与 x 的前两次写行为无关，则当 A 主动 x.release() 时候（即使用 std::memory_order_release），选项 std::memory_order_consume 能够确保 B 在调用 x.load() 时候观察到 A 中第三次对 x 的写操作。

```
	std::atomic<int*> ptr;
	int v;

	std::thread producer([&]() {
		int *p = new int(42);
		v = 1024;
		ptr.store(p,std::memory_order_release);
	});

	std::thread consumer([&]() {
		int* p;
		while (!(p = ptr.load(std::memory_order_consume)));

		std::cout << "p:" << *p << std::endl;
		std::cout << "v:" << v << std::endl;
	});

	producer.join();
	consumer.join();
```

### 释放/获取模型

在此模型下，我们可以进一步加紧对不同线程间原子操作的顺序的限制，在释放 std::memory_order_release 和获取 std::memory_order_acquire 之间规定时序，即发生在释放操作之前的所有写操作，对其他线程的任何获取操作都是可见的，亦即发生顺序（happens-before）。

可以看到，std::memory_order_release 确保了它之后的写行为不会发生在释放操作之前，是一个向后的屏障，而 std::memory_order_acquire 确保了它之后的写行为，不会发生在该获取操作之后，是一个向前的屏障，对于选项 std::memory_order_acq_rel 而言，则结合了这两者的特点，唯一确定了一个内存屏障，使得当前线程对内存的读写不会被重排到此操作的前后。

```
	std::vector<int> v;
	std::atomic<int> flag = { 0 };

	std::thread release([&]() {
		v.push_back(42);
		flag.store(1, std::memory_order_release);
	});

	std::thread acqrel([&]() {
		int expected = 1; //@ must before compare_exchange_strong
		while (!flag.compare_exchange_strong(expected, 2, std::memory_order_acq_rel)) {
			expected = 1; //@ must after compare_exchange_strong
		}
		//@ flag has changed to 2
	});

	std::thread acquire([&]() {
		while (flag.load(std::memory_order_acquire) < 2)
			;

		std::cout << v.at(0) << std::endl; //@ must be 42
	});

	release.join();
	acqrel.join();
	acquire.join();
```

compare_exchange_strong 便是比较交换原语（Compare-and-swap primitive），它有一个更弱的版本，即 compare_exchange_weak，它允许即便交换成功，也仍然返回 false 失败。其原因是因为在某些平台上虚假故障导致的，具体而言，当 CPU 进行上下文切换时，另一线程加载同一地址产生的不一致。除此之外，compare_exchange_strong 的性能可能稍差于 compare_exchange_weak。

### 顺序一致模型

在此模型下，原子操作满足顺序一致性，进而可能对性能产生损耗。可显式的通过 std::memory_order_seq_cst 进行指定。

```
	std::atomic<int> counter = { 0 };
	std::vector<std::thread> vt;
	for (int i = 0; i < 100; ++i) {
		vt.emplace_back([&counter]() {
			counter.fetch_add(1, std::memory_order_seq_cst);
		});
	}

	for (auto& t : vt) {
		t.join();
	}
	std::cout << "current counter:" << counter << std::endl;
```

内存序：

- memory_order_relaxed：松散内存序，只用来保证对原子对象的操作是原子的
- memory_order_consume：目前不鼓励使用  
- memory_order_acquire：获得操作，在读取某原子对象时，当前线程的任何后面的读写操作都不允许重排到这个操作的前面去，并且其他线程在对同一个原子对象释放之前的所有内存写入都在当前线程可见  
- memory_order_release：释放操作，在写入某原子对象时，当前线程的任何前面的读写操作都不允许重排到这个操作的后面去，并且当前线程的所有内存写入都在对同一个原子对象进行获取的其他线程可见  
- memory_order_acq_rel：获得释放操作，一个读‐修改‐写操作同时具有获得语义和释放语义，即它前后的任何读写操作都不允许重排，并且其他线程在对同一个原子对象释放之前的所有内存写入都在当前线程可见，当前线程的所有内存写入都在对同一个原子对象进行获取的其他线程可见  
- memory_order_seq_cst：顺序一致性语义，对于读操作相当于获取，对于写操作相当于释放，对于读‐修改‐写操作相当于获得释放，是所有原子操作的默认内存序  

























